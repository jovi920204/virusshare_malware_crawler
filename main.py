import requests
from bs4 import BeautifulSoup
import os
from time import sleep

success_count = 0
fail_count = 0
search_query = "Allaple"
page = 0

def download_file(url, directory, cookie=None):
    global success_count, fail_count
    sleep(1)
    malware_name = url.split('?')[-1]
    local_filename = os.path.join(directory, url.split('?')[-1] + '.zip')
    with requests.get(url, stream=True, cookies=cookie) as r:
        if r.status_code != 200:
            fail_count += 1
            print(f"!!! Failed to download {malware_name}")
            return 
        else:
            with open(local_filename, 'wb') as f:
                success_count += 1
                print(f"Downloading {malware_name}")
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        return local_filename

def main():
    global search_query, page, success_count, fail_count
    project_dir = os.path.dirname(os.path.abspath(__file__))
    download_directory = os.path.join(project_dir, 'malware_dataset', search_query)

    PHPSESSID='96g09fchq45hh3kiso9b53dd0j'
    auth='L8xyvZcCfyZLhRDZJTLYRGCzpVFGx2g2'

    cookie = {'PHPSESSID': PHPSESSID, 'auth': auth}
    os.makedirs(download_directory, exist_ok=True)

    print("==")
    while success_count < 100:
        print(f"Page: {page}")
        url = "https://virusshare.com/search"
        number = page * 20
        payload = f'search={search_query}&skip={number}'
        print(payload)
        headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.8',
        'Cache-Control': 'max-age=0',
        'Connection': 'keep-alive',
        'Content-Type': 'application/x-www-form-urlencoded',
        'Cookie': f'PHPSESSID={PHPSESSID}; auth={auth}',
        'Origin': 'https://virusshare.com',
        'Referer': 'https://virusshare.com/search',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'same-origin',
        'Sec-Fetch-User': '?1',
        'Sec-GPC': '1',
        'Upgrade-Insecure-Requests': '1',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'sec-ch-ua': '"Not A(Brand";v="99", "Brave";v="121", "Chromium";v="121"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"'
        }

        response = requests.request("POST", url, headers=headers, data=payload)
        print(response.status_code)
        soup = BeautifulSoup(response.text, 'html.parser')

        for link in soup.find_all('a', href=True):
            if link['href'].startswith('download?'):
                virus_name = link['href'].split('?')[-1]
                if os.path.exists(os.path.join(download_directory, virus_name + '.zip')):
                    print(f"File {virus_name} already exists")
                    success_count += 1
                    continue
                file_url = 'https://virusshare.com/' + link['href']
                download_file(file_url, download_directory, cookie)
        page += 1
if __name__ == "__main__":
    main()
    print("========== report ==========")
    print(f"Search Query: {search_query}")
    print(f"Success: {success_count}")
    print(f"Fail: {fail_count}")
    print(f"total: {success_count + fail_count}")